# Developed by dnoobnerd [https://dnoobnerd.netlify.app]    Made with Streamlit
import nltk
nltk.download('stopwords')
#nltk.download('punkt')
from Imports import *


############################## ì½”ìŠ¤ ì¶”ì²œ ê´€ë ¨ ################################
# Core Pkg
import streamlit.components.v1 as stc 

# Load EDA
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity,linear_kernel

# Load Our Dataset
def load_data(data):
	df = pd.read_csv(data)
	return df 


# Fxn
# Vectorize + Cosine Similarity Matrix

def vectorize_text_to_cosine_mat(data):
	count_vect = CountVectorizer()
	cv_mat = count_vect.fit_transform(data)
	# Get the cosine
	cosine_sim_mat = cosine_similarity(cv_mat)
	return cosine_sim_mat



# Recommendation Sys
def get_recommendation(title,cosine_sim_mat,df,num_of_rec=10):
	# indices of the course
	course_indices = pd.Series(df.index,index=df['course_title']).drop_duplicates()
	# Index of course
	idx = course_indices[title]

	# Look into the cosine matr for that index
	sim_scores =list(enumerate(cosine_sim_mat[idx]))
	sim_scores = sorted(sim_scores,key=lambda x: x[1],reverse=True)
	selected_course_indices = [i[0] for i in sim_scores[1:]]
	selected_course_scores = [i[0] for i in sim_scores[1:]]

	# Get the dataframe & title
	result_df = df.iloc[selected_course_indices]
	result_df['similarity_score'] = selected_course_scores
	final_recommended_courses = result_df[['course_title','similarity_score','url','price','num_subscribers']]
	return final_recommended_courses.head(num_of_rec)


RESULT_TEMP = """
<div style="width:90%;height:100%;margin:1px;padding:5px;position:relative;border-radius:5px;border-bottom-right-radius: 60px;
box-shadow:0 0 15px 5px #ccc; background-color: #a8f0c6;
  border-left: 5px solid #6c6c6c;">
<h4>{}</h4>
<p style="color:blue;"><span style="color:black;">ğŸ“ˆScore::</span>{}</p>
<p style="color:blue;"><span style="color:black;">ğŸ”—</span><a href="{}",target="_blank">Link</a></p>
<p style="color:blue;"><span style="color:black;">ğŸ’²Price:</span>{}</p>
<p style="color:blue;"><span style="color:black;">ğŸ§‘â€ğŸ“ğŸ‘¨ğŸ½â€ğŸ“ Students:</span>{}</p>

</div>
"""

# Search For Course 
def search_term_if_not_found(term,df):
	result_df = df[df['course_title'].str.contains(term)]
	return result_df

####################################################################################################



# sql connector
#connection = pymysql.connect(host='localhost',user='root',password='root@MySQL4admin',db='cv')
connection = pymysql.connect(host='localhost',user='root',password='0000',db='mydb') #mysqlê³¼ ì—°ê²°
cursor = connection.cursor()

###### Setting Page Configuration (favicon, Logo, Title) ######
st.set_page_config(
   page_title="AI ì´ë ¥ì„œ ë¶„ì„ê¸°", #í˜ì´ì§€ ì œëª©
   page_icon='./Logo/recommend.png', #í˜ì´ì§€ ë¡œê³ 
)


###### Main function run() ###### 
def run():
    
    # (Logo, Heading, Sidebar etc)
    
    img = Image.open('./Logo/RESUM.png')
    #img = Image.open('./APP/LOGO/RESUM.png')

    st.image(img)
    st.sidebar.markdown("# Choose Something...") 
    activities = ["ì‚¬ìš©ì", "í”¼ë“œë°±", "ì†Œê°œ", "ê´€ë¦¬ì"] # ëª©ë¡
    choice = st.sidebar.selectbox("ì£¼ì–´ì§„ ì˜µì…˜ ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”:", activities)
    link = '<b>Built with ğŸ¤ by <a href="https://dnoobnerd.netlify.app/" style="text-decoration: none; color: #021659;">Deepak Padhi</a></b>' 
    st.sidebar.markdown(link, unsafe_allow_html=True) #ë°©ë¬¸ì ìˆ˜ í‘œì‹œ ë¶€ë¶„
    st.sidebar.markdown('''
        <!-- ì‚¬ì´íŠ¸ ë°©ë¬¸ì -->

        <div id="sfct2xghr8ak6lfqt3kgru233378jya38dy" hidden></div>

        <noscript>
            <a href="https://www.freecounterstat.com" title="hit counter">
                <img src="https://counter9.stat.ovh/private/freecounterstat.php?c=t2xghr8ak6lfqt3kgru233378jya38dy" border="0" title="hit counter" alt="hit counter"> -->
            </a>
        </noscript>
    
        <p>Visitors <img src="https://counter9.stat.ovh/private/freecounterstat.php?c=t2xghr8ak6lfqt3kgru233378jya38dy" title="Free Counter" Alt="web counter" width="60px"  border="0" /></p>
    
    ''', unsafe_allow_html=True)

############################## ìœ ë°ë¯¸ ì½”ìŠ¤ ë°ì´í„° ################################################################# 
    # df for Udemy Course recommendation 
    df = load_data("data/udemy_course_data.csv")
    result_df = pd.DataFrame(columns=['rec_title','rec_score','rec_url', 'rec_price', 'rec_num_sub'])
###############################################################################################################


    ###### Creating Database and Table ######
    # Create the DB
    db_sql = """CREATE DATABASE IF NOT EXISTS CV;"""
    cursor.execute(db_sql)

    # Create table user_data and user_feedback
    # ë°ì´í„°ë² ì´ìŠ¤ì™€ í…Œì´ë¸”ì„ ìƒì„±í•˜ëŠ” SQLì¿¼ë¦¬ ì‹¤í–‰(ì›¹í˜ì´ì§€ ì¶œë ¥ x)
    DB_table_name = 'user_data'
    # í† ìµ, ê¹ƒí—™ì£¼ì†Œ, ë¸”ë¡œê·¸, ë™ì•„ë¦¬, ìê²©ì¦, ê²½ë ¥ ë°ì´í„° ì¶”ê°€
    table_sql = "CREATE TABLE IF NOT EXISTS " + DB_table_name + """
                    (ID INT NOT NULL AUTO_INCREMENT,
                    sec_token varchar(20) NOT NULL,
                    ip_add varchar(50) NULL,
                    host_name varchar(50) NULL,
                    dev_user varchar(50) NULL,
                    os_name_ver varchar(50) NULL,
                    latlong varchar(50) NULL,
                    city varchar(50) NULL,
                    state varchar(50) NULL,
                    country varchar(50) NULL,
                    act_name varchar(50) NOT NULL,
                    act_mail varchar(50) NOT NULL,
                    act_mob varchar(20) NOT NULL,
                    Name varchar(500) NOT NULL,
                    Email_ID VARCHAR(500) NOT NULL,
                    resume_score VARCHAR(8) NOT NULL,
                    Timestamp VARCHAR(50) NOT NULL,
                    Page_no VARCHAR(5) NOT NULL,
                    Predicted_Field BLOB NOT NULL,
                    User_level BLOB NOT NULL,
                    Actual_skills BLOB NOT NULL,
                    Recommended_skills BLOB NOT NULL,
                    Recommended_courses BLOB NOT NULL,
                    pdf_name varchar(50) NOT NULL,
                    toeic varchar(10) NULL, 
                    github_address varchar(100) NULL,
                    blog varchar(100) NULL,
                    club varchar(100) NULL,
                    certificate varchar(500) NULL,
                    PRIMARY KEY (ID)
                    );
                """
    cursor.execute(table_sql)

    

    DBf_table_name = 'user_feedback'
    tablef_sql = "CREATE TABLE IF NOT EXISTS " + DBf_table_name + """
                    (ID INT NOT NULL AUTO_INCREMENT,
                        feed_name varchar(50) NOT NULL,
                        feed_email VARCHAR(50) NOT NULL,
                        feed_score VARCHAR(5) NOT NULL,
                        comments VARCHAR(100) NULL,
                        Timestamp VARCHAR(50) NOT NULL,
                        PRIMARY KEY (ID)
                    );
                """
    cursor.execute(tablef_sql)
    ###### CODE FOR CLIENT SIDE (USER) ######

    

    if choice == 'ì‚¬ìš©ì': # ëª©ë¡ì—ì„œ ì‚¬ìš©ì ì„ íƒí•œ ê²½ìš°
        
        # Collecting Miscellaneous Information
        act_name = st.text_input('ì´ë¦„*')
        act_mail = st.text_input('ì´ë©”ì¼*')
        act_mob  = st.text_input('íœ´ëŒ€í° ë²ˆí˜¸*')
        
        

        if not act_name or not act_mail or not act_mob:
            st.warning("ì´ë¦„, ì´ë©”ì¼ ë° íœ´ëŒ€í° ë²ˆí˜¸ëŠ” í•„ìˆ˜ ì…ë ¥ ì‚¬í•­ì…ë‹ˆë‹¤. ëª¨ë“  í•„ìˆ˜ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            sec_token = secrets.token_urlsafe(12)
            host_name = socket.gethostname()
            ip_add = socket.gethostbyname(host_name)
            dev_user = os.getlogin()
            os_name_ver = platform.system() + " " + platform.release()
            g = geocoder.ip('me')
            latlong = g.latlng #geolocator ëª¨ë“ˆì„ ì´ìš©í•´ ipë¡œ ì§€ë¦¬ìœ„ì¹˜ì •ë³´ íšë“
            geolocator = Nominatim(user_agent="http")
            location = geolocator.reverse(latlong, language='kr')
            address = location.raw['address']
            cityy = address.get('city', '')
            statee = address.get('state', '')
            countryy = address.get('country', '')  
            city = cityy
            state = statee
            country = countryy


            # Upload Resume
            st.markdown('''<h5 style='text-align: left; color: #021659;'> ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ìŠ¤ë§ˆíŠ¸í•œ ì¶”ì²œì„ ë°›ì•„ë³´ì„¸ìš”</h5>''',unsafe_allow_html=True)
            
            ## file upload in pdf format
            pdf_file = st.file_uploader("ì´ë ¥ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”.", type=["pdf"])
            if pdf_file is not None:
                with st.spinner('ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...'):
                    time.sleep(4)
            
                ### saving the uploaded resume to folder
                save_image_path = './Uploaded_Resumes/'+pdf_file.name
                pdf_name = pdf_file.name
                with open(save_image_path, "wb") as f:
                    f.write(pdf_file.getbuffer())
                show_pdf(save_image_path)

                ### parsing and extracting whole resume 
                resume_data = ResumeParser(save_image_path).get_extracted_data()
                resume_url_data = AddParser(save_image_path).get_extracted_data()
                github_address = resume_url_data['github']
                blog = resume_url_data['blog']
                toeic = resume_url_data['toeic']
                certificate = resume_url_data['certificate'] 
                club = 'club'

                if resume_data:
                    
                    ## Get the whole resume data into resume_text
                    resume_text = pdf_reader(save_image_path)

                    ## Showing Analyzed data from (resume_data)
                    st.header("**ì´ë ¥ì„œ ë¶„ì„ ğŸ¤˜**")
                    st.success("ì•ˆë…•í•˜ì„¸ìš” "+ act_name + "ë‹˜")
                    st.subheader("**ê¸°ë³¸ ì •ë³´ ğŸ‘€**")
                    try:
                        st.text('ì´ë¦„: '+ act_name)
                        st.text('ì´ë©”ì¼: ' + act_mail)
                        st.text('ì—°ë½ì²˜: ' + act_mob)                 
                        st.text('ì´ë ¥ì„œ í˜ì´ì§€ ìˆ˜: '+str(resume_data['no_of_pages']))

                    except:
                        pass
                    ## Predicting Candidate Experience Level 

                    ### Trying with different possibilities
                    cand_level = ''
                    if resume_data['no_of_pages'] < 1:                
                        cand_level = "NA"
                        st.markdown( '''<h4 style='text-align: left; color: #d73b5c;'>ë‹¹ì‹ ì€ ì‹ ì… ìˆ˜ì¤€ì…ë‹ˆë‹¤!</h4>''',unsafe_allow_html=True)
                    
                    #### if internship then intermediate level
                    #ì´ë ¥ì„œê°€ í•œê¸€ì´ë¼ ì¡°ê±´ë„ í•œê¸€ì´ ë˜ì–´ì•¼ í•˜ë‚˜í•´ì„œ ì¼ë‹¨ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤
                    elif 'ì¸í„´ì‹­' in resume_text:
                        cand_level = "ì¤‘ê¸‰"
                        st.markdown('''<h4 style='text-align: left; color: #1ed760;'>ë‹¹ì‹ ì€ ì¤‘ê¸‰ ìˆ˜ì¤€ì…ë‹ˆë‹¤!</h4>''',unsafe_allow_html=True)
                    elif 'ì¸í„´ì‰½' in resume_text:
                        cand_level = "ì¤‘ê¸‰"
                        st.markdown('''<h4 style='text-align: left; color: #1ed760;'>ë‹¹ì‹ ì€ ì¤‘ê¸‰ ìˆ˜ì¤€ì…ë‹ˆë‹¤!</h4>''',unsafe_allow_html=True)
                    elif 'Internship' in resume_text:
                        cand_level = "ì¤‘ê¸‰"
                        st.markdown('''<h4 style='text-align: left; color: #1ed760;'>ë‹¹ì‹ ì€ ì¤‘ê¸‰ ìˆ˜ì¤€ì…ë‹ˆë‹¤!</h4>''',unsafe_allow_html=True)
                    elif 'Internships' in resume_text:
                        cand_level = "ì¤‘ê¸‰"
                        st.markdown('''<h4 style='text-align: left; color: #1ed760;'>ë‹¹ì‹ ì€ ì¤‘ê¸‰ ìˆ˜ì¤€ì…ë‹ˆë‹¤!</h4>''',unsafe_allow_html=True)
                    
                    #### if Work Experience/Experience then Experience level
                    elif 'ê²½ë ¥' in resume_text:
                        cand_level = "ê²½í—˜ì"
                        st.markdown('''<h4 style='text-align: left; color: #fba171;'>ë‹¹ì‹ ì€ ê²½ë ¥ì ìˆ˜ì¤€ì…ë‹ˆë‹¤!''',unsafe_allow_html=True)
                    elif 'WORK EXPERIENCE' in resume_text:
                        cand_level = "ê²½í—˜ì"
                        st.markdown('''<h4 style='text-align: left; color: #fba171;'>ë‹¹ì‹ ì€ ê²½ë ¥ì ìˆ˜ì¤€ì…ë‹ˆë‹¤!''',unsafe_allow_html=True)
                    elif 'Experience' in resume_text:
                        cand_level = "ê²½í—˜ì"
                        st.markdown('''<h4 style='text-align: left; color: #fba171;'>ë‹¹ì‹ ì€ ê²½ë ¥ì ìˆ˜ì¤€ì…ë‹ˆë‹¤!''',unsafe_allow_html=True)
                    elif 'Work Experience' in resume_text:
                        cand_level = "ê²½í—˜ì"
                        st.markdown('''<h4 style='text-align: left; color: #fba171;'>ë‹¹ì‹ ì€ ê²½ë ¥ì ìˆ˜ì¤€ì…ë‹ˆë‹¤!''',unsafe_allow_html=True)
                    else:
                        cand_level = "ì‹ ì…"
                        st.markdown('''<h4 style='text-align: left; color: #fba171;'>ë‹¹ì‹ ì€ ì‹ ì… ìˆ˜ì¤€ì…ë‹ˆë‹¤!''',unsafe_allow_html=True)


                    ## Skills Analyzing and Recommendation
                    st.subheader("**ê¸°ìˆ  ì¶”ì²œ ğŸ’¡**")
                    
                    ### Current Analyzed Skills
                    keywords = st_tags(label='### í˜„ì¬ ë³´ìœ í•œ ê¸°ìˆ ',
                    text='ì•„ë˜ì—ì„œ ê¸°ìˆ  ì¶”ì²œì„ í™•ì¸í•˜ì„¸ìš”',value=resume_data['skills'],key = '1  ')

                    ### Keywords for Recommendations
                    ds_keyword = ['tensorflow','keras','pytorch','machine learning','deep Learning','flask','streamlit']
                    web_keyword = ['react', 'django', 'node jS', 'react js', 'php', 'laravel', 'magento', 'wordpress','javascript', 'angular js', 'C#', 'Asp.net', 'flask']
                    android_keyword = ['android','android development','flutter','kotlin','xml','kivy']
                    ios_keyword = ['ios','ios development','swift','cocoa','cocoa touch','xcode']
                    uiux_keyword = ['ux','adobe xd','figma','zeplin','balsamiq','ui','prototyping','wireframes','storyframes','adobe photoshop','photoshop','editing','adobe illustrator','illustrator','adobe after effects','after effects','adobe premier pro','premier pro','adobe indesign','indesign','wireframe','ì…ì²´','íŒŒì•…','ì‚¬ìš©ì ì¡°ì‚¬','ì‚¬ìš©ì ê²½í—˜']
                    n_any = ['ì˜ì–´','ì˜ì‚¬ì†Œí†µ','ê¸€ì“°ê¸°', 'microsoft office ì‘ì—…', 'ë¦¬ë”ì‹­','ê³ ê°ê´€ë¦¬', 'ì†Œì…œ ë¯¸ë””ì–´']
                    ### Skill Recommendations Starts                
                    recommended_skills = []
                    reco_field = ''
                    rec_course = ''

                ########################################################### ì¶”ê°€/ìˆ˜ì •í•œ ë¶€ë¶„ #################################################################

                    ### condition starts to check skills from keywords and predict field
                    for i in resume_data['skills']:
                    
                        #### Data science recommendation
                        if i.lower() in ds_keyword:
                            print(i.lower())
                            reco_field = 'ë°ì´í„° ê³¼í•™'
                            st.success("** ë¶„ì„ ê²°ê³¼ ë°ì´í„° ê³¼í•™ ì§ì¢…ì„ íƒìƒ‰ ì¤‘ì´ë¼ê³  íŒë‹¨ë©ë‹ˆë‹¤.**")
                            recommended_skills = ['ë°ì´í„° ì‹œê°í™”','ì˜ˆì¸¡ ë¶„ì„','í†µê³„ ëª¨ë¸ë§','ë°ì´í„° ë§ˆì´ë‹','í´ëŸ¬ìŠ¤í„°ë§ ë° ë¶„ë¥˜','ë°ì´í„° ë¶„ì„','ì–‘ì  ë¶„ì„','ì›¹ ìŠ¤í¬ë˜í•‘','ë¨¸ì‹  ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜','Keras','Pytorch','í™•ë¥ ','Scikit-learn','Tensorflow',"Flask",'Streamlit']
                            recommended_keywords = st_tags(label='### ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ê¸°ìˆ .',
                            text='ì‹œìŠ¤í…œì—ì„œ ìƒì„±ëœ ì¶”ì²œ ê¸°ìˆ ',value=recommended_skills,key = '2')
                            st.markdown('''<h5 style='text-align: left; color: #1ed760;'>ì´ëŸ¬í•œ ê¸°ìˆ ì„ ì´ë ¥ì„œì— ì¶”ê°€í•˜ë©´ ì·¨ì—… ê¸°íšŒê°€ í–¥ìƒë  ê²ƒ ì…ë‹ˆë‹¤.ğŸš€ </h5>''',unsafe_allow_html=True)
                            # course recommendation
                            rec_course = course_recommender(ds_course)

                            # Udemy recommendation
                            st.subheader("Recommended Udemy Courses")
                            cosine_sim_mat = vectorize_text_to_cosine_mat(df['course_title'])
                            num_of_rec = st.slider("Choose Number of Course Recommendations:",3,30,5)
                            search_terms = ["Data Visualization", "Flask", "Analysis", "Modeling", "Data Analytics"]
                            
                            try:
                                results = get_recommendation(search_terms[0],cosine_sim_mat,df,num_of_rec)

                                for row in results.iterrows():
                                    rec_title = row[1][0]
                                    rec_score = row[1][1]
                                    rec_url = row[1][2]
                                    rec_price = row[1][3]
                                    rec_num_sub = row[1][4]
                                
                                
                                result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                result_df['rec_score'] = pd.Series(rec_score).reset_index(drop=True)
                                result_df['rec_url'] = pd.Series(rec_url).reset_index(drop=True)
                                result_df['rec_price'] = pd.Series(rec_price).reset_index(drop=True)
                                result_df['rec_num_sub'] = pd.Series(rec_num_sub).reset_index(drop=True)


                            except:
                                except_df = search_term_if_not_found(search_terms[0],df)

                                result_df['rec_title'] = pd.concat([result_df['rec_title'], except_df['course_title']], ignore_index=True)
                                result_df['rec_score'] = pd.Series([random.random() for _ in range(except_df.shape[0])])
                                result_df['rec_url'] = except_df['url'].reset_index(drop=True)
                                result_df['rec_price'] = except_df['price'].reset_index(drop=True)
                                result_df['rec_num_sub'] = except_df['num_subscribers'].reset_index(drop=True)

                            
                            for i in range(1, len(search_terms)):
                                search_term = search_terms[i]

                                try:
                                    results = get_recommendation(search_term,cosine_sim_mat,df,num_of_rec)

                                    for row in results.iterrows():
                                        rec_title = row[1][0]
                                        rec_score = row[1][1]
                                        rec_url = row[1][2]
                                        rec_price = row[1][3]
                                        rec_num_sub = row[1][4]
                                    
                                    result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                    result_df['rec_score'] = pd.concat([result_df['rec_score'], pd.Series(rec_score)], ignore_index=True)
                                    result_df['rec_url'] = pd.concat([result_df['rec_url'], pd.Series(rec_url)], ignore_index=True)
                                    result_df['rec_price'] = pd.concat([result_df['rec_price'], pd.Series(rec_price)], ignore_index=True)
                                    result_df['rec_num_sub'] = pd.concat([result_df['rec_num_sub'], pd.Series(rec_num_sub)], ignore_index=True)


                                except:
                                    except_df = search_term_if_not_found(search_term,df)
                                    except_df = except_df.reset_index(drop=True)
                                    result_df = pd.concat([result_df, pd.DataFrame({'rec_title': except_df['course_title'],'rec_score': pd.Series([random.random() for _ in range(except_df.shape[0])]), 'rec_url': except_df['url'], 'rec_price': except_df['price'], 'rec_num_sub': except_df['num_subscribers']})], ignore_index=True)
                            
                            
                            result_df = result_df.sample(frac=1).reset_index(drop=True)

                            for i in range(num_of_rec):       
                                stc.html(RESULT_TEMP.format(result_df['rec_title'].values[i],result_df['rec_score'].values[i],result_df['rec_url'].values[i],result_df['rec_price'].values[i],result_df['rec_num_sub'].values[i]),height=350)

                            break
                        
                        #### Web development recommendation
                        elif i.lower() in web_keyword:
                            print(i.lower())
                            reco_field = 'ì›¹ ê°œë°œ'
                            st.success("**ë¶„ì„ ê²°ê³¼ ì›¹ ê°œë°œ ì§ì¢…ì„ íƒìƒ‰ ì¤‘ì´ë¼ê³  íŒë‹¨ë©ë‹ˆë‹¤. **")
                            recommended_skills = ['React','Django','Node JS','React JS','php','laravel','Magento','wordpress','Javascript','Angular JS','c#','Flask','SDK']
                            recommended_keywords = st_tags(label='### ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ê¸°ìˆ .',
                            text='ì‹œìŠ¤í…œì—ì„œ ìƒì„±ëœ ì¶”ì²œ ê¸°ìˆ ',value=recommended_skills,key = '3')
                            st.markdown('''<h5 style='text-align: left; color: #1ed760;'>ì´ëŸ¬í•œ ê¸°ìˆ ì„ ì´ë ¥ì„œì— ì¶”ê°€í•˜ë©´ ì·¨ì—… ê¸°íšŒê°€ í–¥ìƒë  ê²ƒì…ë‹ˆë‹¤ğŸš€ğŸ’¼</h5>''',unsafe_allow_html=True)
                            # course recommendation
                            rec_course = course_recommender(web_course)

                            # Udemy recommendation
                            st.subheader("Recommended Udemy Courses")
                            cosine_sim_mat = vectorize_text_to_cosine_mat(df['course_title'])
                            num_of_rec = st.slider("Choose Number of Course Recommendations:",3,30,5)
                            search_terms = ["React", "Django", "Node.js", "Javascript", "php"]
                            
                            try:
                                results = get_recommendation(search_terms[0],cosine_sim_mat,df,num_of_rec)

                                for row in results.iterrows():
                                    rec_title = row[1][0]
                                    rec_score = row[1][1]
                                    rec_url = row[1][2]
                                    rec_price = row[1][3]
                                    rec_num_sub = row[1][4]
                                
                                
                                result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                result_df['rec_score'] = pd.Series(rec_score).reset_index(drop=True)
                                result_df['rec_url'] = pd.Series(rec_url).reset_index(drop=True)
                                result_df['rec_price'] = pd.Series(rec_price).reset_index(drop=True)
                                result_df['rec_num_sub'] = pd.Series(rec_num_sub).reset_index(drop=True)


                            except:
                                except_df = search_term_if_not_found(search_terms[0],df)

                                result_df['rec_title'] = pd.concat([result_df['rec_title'], except_df['course_title']], ignore_index=True)
                                result_df['rec_score'] = pd.Series([random.random() for _ in range(except_df.shape[0])])
                                result_df['rec_url'] = except_df['url'].reset_index(drop=True)
                                result_df['rec_price'] = except_df['price'].reset_index(drop=True)
                                result_df['rec_num_sub'] = except_df['num_subscribers'].reset_index(drop=True)

                            
                            for i in range(1, len(search_terms)):
                                search_term = search_terms[i]

                                try:
                                    results = get_recommendation(search_term,cosine_sim_mat,df,num_of_rec)

                                    for row in results.iterrows():
                                        rec_title = row[1][0]
                                        rec_score = row[1][1]
                                        rec_url = row[1][2]
                                        rec_price = row[1][3]
                                        rec_num_sub = row[1][4]
                                    
                                    result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                    result_df['rec_score'] = pd.concat([result_df['rec_score'], pd.Series(rec_score)], ignore_index=True)
                                    result_df['rec_url'] = pd.concat([result_df['rec_url'], pd.Series(rec_url)], ignore_index=True)
                                    result_df['rec_price'] = pd.concat([result_df['rec_price'], pd.Series(rec_price)], ignore_index=True)
                                    result_df['rec_num_sub'] = pd.concat([result_df['rec_num_sub'], pd.Series(rec_num_sub)], ignore_index=True)


                                except:
                                    except_df = search_term_if_not_found(search_term,df)
                                    except_df = except_df.reset_index(drop=True)
                                    result_df = pd.concat([result_df, pd.DataFrame({'rec_title': except_df['course_title'],'rec_score': pd.Series([random.random() for _ in range(except_df.shape[0])]), 'rec_url': except_df['url'], 'rec_price': except_df['price'], 'rec_num_sub': except_df['num_subscribers']})], ignore_index=True)
                            
                            
                            result_df = result_df.sample(frac=1).reset_index(drop=True)

                            for i in range(num_of_rec):       
                                stc.html(RESULT_TEMP.format(result_df['rec_title'].values[i],result_df['rec_score'].values[i],result_df['rec_url'].values[i],result_df['rec_price'].values[i],result_df['rec_num_sub'].values[i]),height=350)

                            break

                        #### Android App Development
                        elif i.lower() in android_keyword:
                            print(i.lower())
                            reco_field = 'ì•ˆë“œë¡œì´ë“œ ì•± ê°œë°œ'
                            st.success("** ë¶„ì„ ê²°ê³¼ ì•ˆë“œë¡œì´ë“œ ì•± ê°œë°œ ì§ì¢…ì„ íƒìƒ‰ ì¤‘ì´ë¼ê³  íŒë‹¨ë©ë‹ˆë‹¤. **")
                            recommended_skills = ['Android','Android development','Flutter','Kotlin','XML','Java','Kivy','GIT','SDK','SQLite']
                            recommended_keywords = st_tags(label='### ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ê¸°ìˆ ',
                            text='ì‹œìŠ¤í…œì—ì„œ ìƒì„±ëœ ì¶”ì²œ ê¸°ìˆ ',value=recommended_skills,key = '4')
                            st.markdown('''<h5 style='text-align: left; color: #1ed760;'>ì´ëŸ¬í•œ ê¸°ìˆ ì„ ì´ë ¥ì„œì— ì¶”ê°€í•˜ë©´ ì·¨ì—… ê¸°íšŒê°€ í–¥ìƒë  ê²ƒì…ë‹ˆë‹¤ğŸš€ğŸ’¼</h5>''',unsafe_allow_html=True)
                            # course recommendation
                            rec_course = course_recommender(android_course)
                            
                            # Udemy recommendation
                            st.subheader("Recommended Udemy Courses")
                            cosine_sim_mat = vectorize_text_to_cosine_mat(df['course_title'])
                            num_of_rec = st.slider("Choose Number of Course Recommendations:",3,30,5)
                            search_terms = ["Android", "XML", "Java", "SQL", "Javascript"]
                            
                            try:
                                results = get_recommendation(search_terms[0],cosine_sim_mat,df,num_of_rec)

                                for row in results.iterrows():
                                    rec_title = row[1][0]
                                    rec_score = row[1][1]
                                    rec_url = row[1][2]
                                    rec_price = row[1][3]
                                    rec_num_sub = row[1][4]
                                
                                
                                result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                result_df['rec_score'] = pd.Series(rec_score).reset_index(drop=True)
                                result_df['rec_url'] = pd.Series(rec_url).reset_index(drop=True)
                                result_df['rec_price'] = pd.Series(rec_price).reset_index(drop=True)
                                result_df['rec_num_sub'] = pd.Series(rec_num_sub).reset_index(drop=True)


                            except:
                                except_df = search_term_if_not_found(search_terms[0],df)

                                result_df['rec_title'] = pd.concat([result_df['rec_title'], except_df['course_title']], ignore_index=True)
                                result_df['rec_score'] = pd.Series([random.random() for _ in range(except_df.shape[0])])
                                result_df['rec_url'] = except_df['url'].reset_index(drop=True)
                                result_df['rec_price'] = except_df['price'].reset_index(drop=True)
                                result_df['rec_num_sub'] = except_df['num_subscribers'].reset_index(drop=True)

                            
                            for i in range(1, len(search_terms)):
                                search_term = search_terms[i]

                                try:
                                    results = get_recommendation(search_term,cosine_sim_mat,df,num_of_rec)

                                    for row in results.iterrows():
                                        rec_title = row[1][0]
                                        rec_score = row[1][1]
                                        rec_url = row[1][2]
                                        rec_price = row[1][3]
                                        rec_num_sub = row[1][4]
                                    
                                    result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                    result_df['rec_score'] = pd.concat([result_df['rec_score'], pd.Series(rec_score)], ignore_index=True)
                                    result_df['rec_url'] = pd.concat([result_df['rec_url'], pd.Series(rec_url)], ignore_index=True)
                                    result_df['rec_price'] = pd.concat([result_df['rec_price'], pd.Series(rec_price)], ignore_index=True)
                                    result_df['rec_num_sub'] = pd.concat([result_df['rec_num_sub'], pd.Series(rec_num_sub)], ignore_index=True)


                                except:
                                    except_df = search_term_if_not_found(search_term,df)
                                    except_df = except_df.reset_index(drop=True)
                                    result_df = pd.concat([result_df, pd.DataFrame({'rec_title': except_df['course_title'],'rec_score': pd.Series([random.random() for _ in range(except_df.shape[0])]), 'rec_url': except_df['url'], 'rec_price': except_df['price'], 'rec_num_sub': except_df['num_subscribers']})], ignore_index=True)
                            
                            
                            result_df = result_df.sample(frac=1).reset_index(drop=True)

                            for i in range(num_of_rec):       
                                stc.html(RESULT_TEMP.format(result_df['rec_title'].values[i],result_df['rec_score'].values[i],result_df['rec_url'].values[i],result_df['rec_price'].values[i],result_df['rec_num_sub'].values[i]),height=350)

                            break

                        #### IOS App Development
                        elif i.lower() in ios_keyword:
                            print(i.lower())
                            reco_field = 'IOS ì•± ê°œë°œ'
                            st.success("**ë¶„ì„ ê²°ê³¼ iOS ì•± ê°œë°œ ì§ì¢…ì„ íƒìƒ‰ ì¤‘ì´ë¼ê³  íŒë‹¨ë©ë‹ˆë‹¤. **")
                            recommended_skills = ['IOS','IOS Development','Swift','Cocoa','Cocoa Touch','Xcode','Objective-C','SQLite','Plist','StoreKit',"UI-Kit",'AV Foundation','Auto-Layout']
                            recommended_keywords = st_tags(label='### ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ê¸°ìˆ ',
                            text='ì‹œìŠ¤í…œì—ì„œ ìƒì„±ëœ ì¶”ì²œ ê¸°ìˆ ',value=recommended_skills,key = '5')
                            st.markdown('''<h5 style='text-align: left; color: #1ed760;'>ì´ëŸ¬í•œ ê¸°ìˆ ì„ ì´ë ¥ì„œì— ì¶”ê°€í•˜ë©´ ì·¨ì—… ê¸°íšŒê°€ í–¥ìƒë  ê²ƒì…ë‹ˆë‹¤ğŸš€ğŸ’¼</h5>''',unsafe_allow_html=True)
                            # course recommendation
                            rec_course = course_recommender(ios_course)
                            
                            # Udemy recommendation
                            st.subheader("Recommended Udemy Courses")
                            cosine_sim_mat = vectorize_text_to_cosine_mat(df['course_title'])
                            num_of_rec = st.slider("Choose Number of Course Recommendations:",3,30,5)
                            search_terms = ["IOS", "Swift", "SQL", "Firebase", "git"]
                            
                            try:
                                results = get_recommendation(search_terms[0],cosine_sim_mat,df,num_of_rec)

                                for row in results.iterrows():
                                    rec_title = row[1][0]
                                    rec_score = row[1][1]
                                    rec_url = row[1][2]
                                    rec_price = row[1][3]
                                    rec_num_sub = row[1][4]
                                
                                
                                result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                result_df['rec_score'] = pd.Series(rec_score).reset_index(drop=True)
                                result_df['rec_url'] = pd.Series(rec_url).reset_index(drop=True)
                                result_df['rec_price'] = pd.Series(rec_price).reset_index(drop=True)
                                result_df['rec_num_sub'] = pd.Series(rec_num_sub).reset_index(drop=True)


                            except:
                                except_df = search_term_if_not_found(search_terms[0],df)

                                result_df['rec_title'] = pd.concat([result_df['rec_title'], except_df['course_title']], ignore_index=True)
                                result_df['rec_score'] = pd.Series([random.random() for _ in range(except_df.shape[0])])
                                result_df['rec_url'] = except_df['url'].reset_index(drop=True)
                                result_df['rec_price'] = except_df['price'].reset_index(drop=True)
                                result_df['rec_num_sub'] = except_df['num_subscribers'].reset_index(drop=True)

                            
                            for i in range(1, len(search_terms)):
                                search_term = search_terms[i]

                                try:
                                    results = get_recommendation(search_term,cosine_sim_mat,df,num_of_rec)

                                    for row in results.iterrows():
                                        rec_title = row[1][0]
                                        rec_score = row[1][1]
                                        rec_url = row[1][2]
                                        rec_price = row[1][3]
                                        rec_num_sub = row[1][4]
                                    
                                    result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                    result_df['rec_score'] = pd.concat([result_df['rec_score'], pd.Series(rec_score)], ignore_index=True)
                                    result_df['rec_url'] = pd.concat([result_df['rec_url'], pd.Series(rec_url)], ignore_index=True)
                                    result_df['rec_price'] = pd.concat([result_df['rec_price'], pd.Series(rec_price)], ignore_index=True)
                                    result_df['rec_num_sub'] = pd.concat([result_df['rec_num_sub'], pd.Series(rec_num_sub)], ignore_index=True)


                                except:
                                    except_df = search_term_if_not_found(search_term,df)
                                    except_df = except_df.reset_index(drop=True)
                                    result_df = pd.concat([result_df, pd.DataFrame({'rec_title': except_df['course_title'],'rec_score': pd.Series([random.random() for _ in range(except_df.shape[0])]), 'rec_url': except_df['url'], 'rec_price': except_df['price'], 'rec_num_sub': except_df['num_subscribers']})], ignore_index=True)
                            
                            
                            result_df = result_df.sample(frac=1).reset_index(drop=True)

                            for i in range(num_of_rec):       
                                stc.html(RESULT_TEMP.format(result_df['rec_title'].values[i],result_df['rec_score'].values[i],result_df['rec_url'].values[i],result_df['rec_price'].values[i],result_df['rec_num_sub'].values[i]),height=350)

                            break

                        #### Ui-UX Recommendation
                        elif i.lower() in uiux_keyword:
                            print(i.lower())
                            reco_field = 'UI-UX ê°œë°œ'
                            st.success("** ë¶„ì„ ê²°ê³¼ UI-UX ê°œë°œ ì§ì¢…ì„ íƒìƒ‰ ì¤‘ì´ë¼ê³  íŒë‹¨ë©ë‹ˆë‹¤. **")
                            recommended_skills = ['UI','User Experience','Adobe XD','Figma','Zeplin','Balsamiq','Prototyping','Wireframes','Storyframes','Adobe Photoshop','Editing','Illustrator','After Effects','Premier Pro','Indesign','Wireframe','Solid','Grasp','User Research']
                            recommended_keywords = st_tags(label='### ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ê¸°ìˆ  ',
                            text='ì‹œìŠ¤í…œì—ì„œ ìƒì„±ëœ ì¶”ì²œ ê¸°ìˆ ',value=recommended_skills,key = '6')
                            st.markdown('''<h5 style='text-align: left; color: #1ed760;'>ì´ëŸ¬í•œ ê¸°ìˆ ì„ ì´ë ¥ì„œì— ì¶”ê°€í•˜ë©´ ì·¨ì—… ê¸°íšŒê°€ í–¥ìƒë  ê²ƒì…ë‹ˆë‹¤ğŸš€ğŸ’¼</h5>''',unsafe_allow_html=True)
                            # course recommendation
                            rec_course = course_recommender(uiux_course)
                            
                            # Udemy recommendation
                            st.subheader("Recommended Udemy Courses")
                            cosine_sim_mat = vectorize_text_to_cosine_mat(df['course_title'])
                            num_of_rec = st.slider("Choose Number of Course Recommendations:",3,30,5)
                            search_terms = ["UI", "Adobe", "UX", "Illustrator", "Editing"]
                            
                            try:
                                results = get_recommendation(search_terms[0],cosine_sim_mat,df,num_of_rec)

                                for row in results.iterrows():
                                    rec_title = row[1][0]
                                    rec_score = row[1][1]
                                    rec_url = row[1][2]
                                    rec_price = row[1][3]
                                    rec_num_sub = row[1][4]
                                
                                
                                result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                result_df['rec_score'] = pd.Series(rec_score).reset_index(drop=True)
                                result_df['rec_url'] = pd.Series(rec_url).reset_index(drop=True)
                                result_df['rec_price'] = pd.Series(rec_price).reset_index(drop=True)
                                result_df['rec_num_sub'] = pd.Series(rec_num_sub).reset_index(drop=True)


                            except:
                                except_df = search_term_if_not_found(search_terms[0],df)

                                result_df['rec_title'] = pd.concat([result_df['rec_title'], except_df['course_title']], ignore_index=True)
                                result_df['rec_score'] = pd.Series([random.random() for _ in range(except_df.shape[0])])
                                result_df['rec_url'] = except_df['url'].reset_index(drop=True)
                                result_df['rec_price'] = except_df['price'].reset_index(drop=True)
                                result_df['rec_num_sub'] = except_df['num_subscribers'].reset_index(drop=True)

                            
                            for i in range(1, len(search_terms)):
                                search_term = search_terms[i]

                                try:
                                    results = get_recommendation(search_term,cosine_sim_mat,df,num_of_rec)

                                    for row in results.iterrows():
                                        rec_title = row[1][0]
                                        rec_score = row[1][1]
                                        rec_url = row[1][2]
                                        rec_price = row[1][3]
                                        rec_num_sub = row[1][4]
                                    
                                    result_df['rec_title'] = pd.concat([result_df['rec_title'], pd.Series(rec_title)], ignore_index=True)
                                    result_df['rec_score'] = pd.concat([result_df['rec_score'], pd.Series(rec_score)], ignore_index=True)
                                    result_df['rec_url'] = pd.concat([result_df['rec_url'], pd.Series(rec_url)], ignore_index=True)
                                    result_df['rec_price'] = pd.concat([result_df['rec_price'], pd.Series(rec_price)], ignore_index=True)
                                    result_df['rec_num_sub'] = pd.concat([result_df['rec_num_sub'], pd.Series(rec_num_sub)], ignore_index=True)


                                except:
                                    except_df = search_term_if_not_found(search_term,df)
                                    except_df = except_df.reset_index(drop=True)
                                    result_df = pd.concat([result_df, pd.DataFrame({'rec_title': except_df['course_title'],'rec_score': pd.Series([random.random() for _ in range(except_df.shape[0])]), 'rec_url': except_df['url'], 'rec_price': except_df['price'], 'rec_num_sub': except_df['num_subscribers']})], ignore_index=True)
                            
                            
                            result_df = result_df.sample(frac=1).reset_index(drop=True)

                            for i in range(num_of_rec):       
                                stc.html(RESULT_TEMP.format(result_df['rec_title'].values[i],result_df['rec_score'].values[i],result_df['rec_url'].values[i],result_df['rec_price'].values[i],result_df['rec_num_sub'].values[i]),height=350)

                            break

                        #### For Not Any Recommendations
                        elif i.lower() in n_any:
                            print(i.lower())
                            reco_field = 'NA'
                            st.warning("** í˜„ì¬ ìš°ë¦¬ ë„êµ¬ëŠ” ë°ì´í„° ê³¼í•™, ì›¹, ì•ˆë“œë¡œì´ë“œ, iOS ë° UI/UX ê°œë°œì— ëŒ€í•´ì„œë§Œ ì˜ˆì¸¡ ë° ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤. **")
                            recommended_skills = ['ì¶”ì²œ ì—†ìŒ']
                            recommended_keywords = st_tags(label='### ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ê¸°ìˆ ',
                            text='í˜„ì¬ ì¶”ì²œ ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤. ',value=recommended_skills,key = '6')
                            st.markdown('''<h5 style='text-align: left; color: #092851;'>í–¥í›„ ì—…ë°ì´íŠ¸ì—ì„œ ì¶”ê°€ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤</h5>''',unsafe_allow_html=True)
                            # course recommendation
                            rec_course = "Sì£„ì†¡í•©ë‹ˆë‹¤! ì´ ë¶„ì•¼ì— ëŒ€í•œ ì¶”ì²œì´ í˜„ì¬ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. "
                            break


                    ## Resume Scorer & Resume Writing Tips
                    st.subheader("**ì´ë ¥ì„œ ì‘ì„± íŒ & ì•„ì´ë””ì–´ ğŸ¥‚**")
                    resume_score = 0
                    
                    ### Predicting Whether these key points are added to the resume
                    if 'ë¸”ë¡œê·¸' or 'blog' or 'ë¸”ë¡œê·¸' in resume_text:
                        resume_score = resume_score+6
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê¸°ìˆ  ë¸”ë¡œê·¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)                
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ê¸°ìˆ  ë¸”ë¡œê·¸ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì±„ìš© ë‹´ë‹¹ìì—ê²Œ ê·€í•˜ì˜ ê¸°ìˆ  ì„±ì¥ ê³¼ì •ì„ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'êµìœ¡' or 'í•™êµ' or 'ëŒ€í•™'  in resume_text:
                        resume_score = resume_score + 12
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! êµìœ¡ ì„¸ë¶€ ì •ë³´ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] êµìœ¡ ì„¸ë¶€ ì •ë³´ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì±„ìš© ë‹´ë‹¹ìì—ê²Œ ê·€í•˜ì˜ ìê²© ìˆ˜ì¤€ì„ ì•Œë ¤ì¤„ ê²ƒì…ë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'ê²½ë ¥' in resume_text:
                        resume_score = resume_score + 16
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê²½ë ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Experience' in resume_text:
                        resume_score = resume_score + 16
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê²½ë ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ê²½ë ¥ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ë‹¤ë¥¸ ì§€ì›ìë“¤ê³¼ ì°¨ë³„í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'ì¸í„´ì‹­'  in resume_text:
                        resume_score = resume_score + 6
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì¸í„´ì‹­ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'ì¸í„´ì‰½'  in resume_text:
                        resume_score = resume_score + 6
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì¸í„´ì‰½ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Internships'  in resume_text:
                        resume_score = resume_score + 6
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì¸í„´ì‰½ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Internship'  in resume_text:
                        resume_score = resume_score + 6
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì¸í„´ì‰½ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ì¸í„´ì‰½ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ë‹¤ë¥¸ ì§€ì›ìë“¤ê³¼ ì°¨ë³„í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'ê¸°ìˆ '  in resume_text:
                        resume_score = resume_score + 11
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê¸°ìˆ ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'SKILL'  in resume_text:
                        resume_score = resume_score + 11
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê¸°ìˆ ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Skills'  in resume_text:
                        resume_score = resume_score + 11
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê¸°ìˆ ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Skill'  in resume_text:
                        resume_score = resume_score + 11
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê¸°ìˆ ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ê¸°ìˆ ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì—¬ëŸ¬ë¶„ì„ ë„ìš¸ ë§¤ìš° ì¤‘ìš”í•œ ì •ë³´ì…ë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'ì·¨ë¯¸' or 'íŠ¹ê¸°' in resume_text:
                        resume_score = resume_score + 4
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì·¨ë¯¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Hobbies' in resume_text:
                        resume_score = resume_score + 4
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì·¨ë¯¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ì·¨ë¯¸ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì—¬ëŸ¬ë¶„ì˜ ì„±ê²©ì„ ì±„ìš© ë‹´ë‹¹ìì—ê²Œ ë³´ì—¬ì£¼ê³ , ì´ ì—­í• ì— ì í•©í•œì§€ ì—¬ë¶€ë¥¼ ë³´ì—¬ì¤„ ê²ƒì…ë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'ê´€ì‹¬ì‚¬' in resume_text:
                        resume_score = resume_score + 5
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê´€ì‹¬ì‚¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Interests'in resume_text:
                        resume_score = resume_score + 5
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ê´€ì‹¬ì‚¬ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ê´€ì‹¬ì‚¬ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì±„ìš© ë‹´ë‹¹ìì—ê²Œ ì—¬ëŸ¬ë¶„ì˜ ì—…ë¬´ ì™¸ ê´€ì‹¬ì‚¬ë¥¼ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'ì„±ì·¨' or 'ì„±ê³¼' in resume_text:
                        resume_score = resume_score + 6
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì„±ì·¨ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. </h4>''',unsafe_allow_html=True)
                    elif 'Achievements' in resume_text:
                        resume_score = resume_score + 6
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ì„±ì·¨ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. </h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ì„±ì·¨ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì—¬ëŸ¬ë¶„ì´ í•„ìš”í•œ ì—…ë¬´ì— ì í•©í•œ ëŠ¥ë ¥ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'ìê²©ì¦' in resume_text:
                        resume_score = resume_score + 8
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ìê²©ì¦ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. </h4>''',unsafe_allow_html=True)
                    elif 'Certifications' in resume_text:
                        resume_score = resume_score + 8
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ìê²©ì¦ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. </h4>''',unsafe_allow_html=True)
                    elif 'Certification' in resume_text:
                        resume_score = resume_score + 8
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! ìê²©ì¦ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. </h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] ìê²©ì¦ì„ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì—¬ëŸ¬ë¶„ì´ í•„ìš”í•œ ì—…ë¬´ì— ëŒ€í•´ ì „ë¬¸ ì§€ì‹ì„ ê°–ê³  ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    if 'í”„ë¡œì íŠ¸' in resume_text:
                        resume_score = resume_score + 26
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! í”„ë¡œì íŠ¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'PROJECT' in resume_text:
                        resume_score = resume_score + 26
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! í”„ë¡œì íŠ¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Projects' in resume_text:
                        resume_score = resume_score + 26
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! í”„ë¡œì íŠ¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    elif 'Project' in resume_text:
                        resume_score = resume_score + 26
                        st.markdown('''<h5 style='text-align: left; color: #1ed760;'>[+] í›Œë¥­í•©ë‹ˆë‹¤! í”„ë¡œì íŠ¸ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)
                    else:
                        st.markdown('''<h5 style='text-align: left; color: #000000;'>[-] í”„ë¡œì íŠ¸ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”. ì´ê²ƒì€ ì—¬ëŸ¬ë¶„ì´ í•„ìš”í•œ ì—…ë¬´ì™€ ê´€ë ¨ëœ ì‘ì—…ì„ ìˆ˜í–‰í–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</h4>''',unsafe_allow_html=True)

                    st.subheader("**ì´ë ¥ì„œ ì ìˆ˜ ğŸ“**")
                    
                    st.markdown(
                        """
                        <style>
                            .stProgress > div > div > div > div {
                                background-color: #d73b5c;
                            }
                        </style>""",
                        unsafe_allow_html=True,
                    )

                    ### Score Bar
                    my_bar = st.progress(0)
                    score = 0
                    for percent_complete in range(resume_score):
                        score +=1
                        time.sleep(0.1)
                        my_bar.progress(percent_complete + 1)

                    ### Score
                    st.success('** ì´ë ¥ì„œ ì‘ì„± ì ìˆ˜: ' + str(score)+'**')
                    st.warning("** ì°¸ê³ : ì´ ì ìˆ˜ëŠ” ì´ë ¥ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. **")

                    # print(str(sec_token), str(ip_add), (host_name), (dev_user), (os_name_ver), (latlong), (city), (state), (country), (act_name), (act_mail), (act_mob), resume_data['name'], resume_data['email'], str(resume_score), timestamp, str(resume_data['no_of_pages']), reco_field, cand_level, str(resume_data['skills']), str(recommended_skills), str(rec_course), pdf_name)


                    ### Getting Current Date and Time
                    ts = time.time()
                    cur_date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
                    cur_time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
                    timestamp = str(cur_date+'_'+cur_time)


                    ## Calling insert_data to add all the data into user_data                
                    insert_data(cursor, connection, str(sec_token), str(ip_add), (host_name), (dev_user), (os_name_ver), (latlong), (city), (state), (country), (act_name), (act_mail), (act_mob), resume_data['name'], resume_data['email'], str(resume_score), timestamp, str(resume_data['no_of_pages']), reco_field, cand_level, str(resume_data['skills']), str(recommended_skills), str(rec_course), pdf_name, str(toeic), str(github_address), str(blog), str(club), str(certificate))

                    ## Recommending Resume Writing Video
                    #st.header("**Bonus Video for Resume Writing TipsğŸ’¡**")
                    st.header("**ì´ë ¥ì„œ ì‘ì„±ì„ ìœ„í•œ ë³´ë„ˆìŠ¤ ì˜ìƒğŸ’¡**")
                    resume_vid = random.choice(resume_videos) # ëœë¤ìœ¼ë¡œ ì„ íƒ
                    st.video(resume_vid)

                    ## Recommending Interview Preparation Video
                    #st.header("**Bonus Video for Interview TipsğŸ’¡**")
                    st.header("**ë©´ì ‘ì„ ìœ„í•œ ë³´ë„ˆìŠ¤ ì˜ìƒğŸ’¡**")
                    interview_vid = random.choice(interview_videos) # ëœë¤ìœ¼ë¡œ ì„ íƒ
                    st.video(interview_vid)

                    ## On Successful Result 
              
                # st.balloons()
                else:
                    st.error('ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤...')                


    ###### CODE FOR FEEDBACK SIDE ######
    elif choice == 'í”¼ë“œë°±':   
        
        # timestamp 
        ts = time.time()
        cur_date = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
        cur_time = datetime.datetime.fromtimestamp(ts).strftime('%H:%M:%S')
        timestamp = str(cur_date+'_'+cur_time)

        # Feedback Form
        with st.form("my_form"):
            st.write("í”¼ë“œë°± ì–‘ì‹")            
            feed_name = st.text_input('ì´ë¦„')
            feed_email = st.text_input('ì´ë©”ì¼')
            feed_score = st.slider('ì ìˆ˜ë¥¼ ë©”ê²¨ì£¼ì„¸ìš”. (1 ì—ì„œ 5)', 1, 5)
            comments = st.text_input('ì˜ê²¬')
            Timestamp = timestamp        
            submitted = st.form_submit_button("ì œì¶œ")
            if submitted:
                ## Calling insertf_data to add dat into user feedback
                insertf_data(cursor, connection, feed_name,feed_email,feed_score,comments,Timestamp)    
                ## Success Message 
                st.success("ê°ì‚¬í•©ë‹ˆë‹¤! ë‹¹ì‹ ì˜ í”¼ë“œë°±ì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.") 
                ## On Successful Submit
                st.balloons()    


        # query to fetch data from user feedback table
        query = 'select * from user_feedback'        
        plotfeed_data = pd.read_sql(query, connection)                        


        # fetching feed_score from the query and getting the unique values and total value count 
        labels = plotfeed_data.feed_score.unique()
        values = plotfeed_data.feed_score.value_counts()


        # plotting pie chart for user ratings
        st.subheader("**ê³¼ê±° ì‚¬ìš©ì ë“±ê¸‰**")
        fig = px.pie(values=values, names=labels, title="1ì—ì„œ 5ê¹Œì§€ì˜ ì‚¬ìš©ì ë“±ê¸‰ ì°¨íŠ¸", color_discrete_sequence=px.colors.sequential.Aggrnyl)
        st.plotly_chart(fig)


        #  Fetching Comment History
        cursor.execute('select feed_name, comments from user_feedback')
        plfeed_cmt_data = cursor.fetchall()

        st.subheader("**ì‚¬ìš©ì ëŒ“ê¸€**")
        dff = pd.DataFrame(plfeed_cmt_data, columns=['ì‚¬ìš©ì', 'ëŒ“ê¸€'])
        st.dataframe(dff, width=1000)

    
    ###### CODE FOR ABOUT PAGE ######
    elif choice == 'ì†Œê°œ':   

        st.subheader("**íˆ´ ì†Œê°œ - AI ì´ë ¥ì„œ ë¶„ì„ê¸°**")

        st.markdown('''

        <p align='justify'>
            ìì—°ì–´ ì²˜ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë ¥ì„œì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  í‚¤ì›Œë“œë¥¼ ì°¾ì•„ ê·¸ë“¤ì„ í‚¤ì›Œë“œì— ê¸°ë°˜í•˜ì—¬ ì„¹í„°ë¡œ í´ëŸ¬ìŠ¤í„°ë§í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­ì„ ê¸°ë°˜ìœ¼ë¡œ ì§€ì›ìì—ê²Œ ê¶Œì¥ ì‚¬í•­, ì˜ˆì¸¡ ë° ë¶„ì„ì„ í‘œì‹œí•©ë‹ˆë‹¤.
        </p>

        <p align="justify">
            <b>ì‚¬ìš© ë°©ë²•: -</b> <br/><br/>
            <b>ì‚¬ìš©ì -</b> <br/>
            ì‚¬ì´ë“œ ë°”ì—ì„œ ì‚¬ìš©ìë¡œ ìì‹ ì„ ì„ íƒí•˜ê³  í•„ìˆ˜ í•„ë“œë¥¼ ì‘ì„±í•˜ê³  ì´ë ¥ì„œë¥¼ PDF í˜•ì‹ìœ¼ë¡œ ì—…ë¡œë“œí•˜ì‹­ì‹œì˜¤.<br/>
            ê·¸ëƒ¥ ì•‰ì•„ì„œ ê¸°ë‹¤ë¦¬ì„¸ìš”. ìš°ë¦¬ì˜ ë„êµ¬ê°€ ìŠ¤ìŠ¤ë¡œ ë§ˆë²•ì„ ë¶€ë¦½ë‹ˆë‹¤.<br/><br/>
            <b>í”¼ë“œë°± -</b> <br/>
            ì‚¬ìš©ìê°€ ë„êµ¬ì— ëŒ€í•œ ì˜ê²¬ì„ ì œì•ˆí•  ìˆ˜ ìˆëŠ” ê³³ì…ë‹ˆë‹¤.<br/><br/>
            <b>ê´€ë¦¬ì -</b> <br/>
            ë¡œê·¸ì¸ì—ëŠ” ì‚¬ìš©ì ì´ë¦„ìœ¼ë¡œ <b>admin</b> ë° ë¹„ë°€ë²ˆí˜¸ë¡œ <b>admin@resume-analyzer</b>ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.<br/>
            í•„ìš”í•œ ëª¨ë“  ê²ƒì„ë¡œë“œí•˜ê³  ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        </p><br/><br/>

        <p align="justify">
            Built with ğŸ¤ by 
            <a href="https://dnoobnerd.netlify.app/" style="text-decoration: none; color: grey;">Deepak Padhi</a> through 
            <a href="https://www.linkedin.com/in/mrbriit/" style="text-decoration: none; color: grey;">Dr Bright --(Data Scientist)</a>
        </p>

        ''',unsafe_allow_html=True)  


    ###### CODE FOR ADMIN SIDE (ADMIN) ######
    else:
        st.success('ê´€ë¦¬ì í˜ì´ì§€ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.')

        #  Admin Login
        ad_user = st.text_input("ì‚¬ìš©ì ì´ë¦„")
        ad_password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type='password')

        if st.button('ë¡œê·¸ì¸'):
            
            ## Credentials 
            if ad_user == 'admin' and ad_password == 'admin@resume-analyzer':
                
                ### Fetch miscellaneous data from user_data(table) and convert it into dataframe
                cursor.execute('''SELECT ID, ip_add, resume_score, convert(Predicted_Field using utf8), convert(User_level using utf8), city, state, country from user_data''')
                datanalys = cursor.fetchall()
                plot_data = pd.DataFrame(datanalys, columns=['Idt', 'IP_add', 'resume_score', 'Predicted_Field', 'User_Level', 'City', 'State', 'Country',])
                
                ### Total Users Count with a Welcome Message
                values = plot_data.Idt.count()
                st.success("ê´€ë¦¬ìë‹˜ í™˜ì˜í•©ë‹ˆë‹¤! ì´ %d " % values + "ëª…ì˜ ì‚¬ìš©ìê°€ ìš°ë¦¬ ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤ : )")                
                
                ### Fetch user data from user_data(table) and convert it into dataframe
                cursor.execute('''SELECT ID, sec_token, ip_add, act_name, act_mail, act_mob, convert(Predicted_Field using utf8), Timestamp, Name, Email_ID, resume_score, Page_no, pdf_name, convert(User_level using utf8), convert(Actual_skills using utf8), convert(Recommended_skills using utf8), convert(Recommended_courses using utf8), city, state, country, latlong, os_name_ver, host_name, dev_user, toeic, github_address, blog, club, certificate from user_data''')
                data = cursor.fetchall()                

                st.header("**ì‚¬ìš©ì ë°ì´í„°**")
                df = pd.DataFrame(data, columns=['ID', 'Token', 'IP ì£¼ì†Œ', 'ì´ë¦„', 'ë©”ì¼', 'ì „í™”ë²ˆí˜¸', 'ì˜ˆì¸¡ëœ ë¶„ì•¼', 'íƒ€ì„ìŠ¤íƒ¬í”„',
                                             'ì˜ˆì¸¡ëœ ì´ë¦„', 'ì˜ˆì¸¡ëœ ë©”ì¼', 'ì´ë ¥ì„œ ì ìˆ˜', 'ì´ í˜ì´ì§€',  'íŒŒì¼ ì´ë¦„',   
                                             'ì‚¬ìš©ì ë ˆë²¨', 'ì‹¤ì œ ê¸°ìˆ ', 'ê¶Œì¥ ê¸°ìˆ ', 'ê¶Œì¥ ì½”ìŠ¤',
                                             'ë„ì‹œ', 'í–‰ì • êµ¬ì—­(ë„)', 'êµ­ê°€', 'ìœ„ë„ ê²½ë„', 'ì„œë²„ OS', 'ì„œë²„ ì´ë¦„', 'ì„œë²„ ì‚¬ìš©ì', 'í† ìµ', 'ê¹ƒí—ˆë¸Œ', 'ë¸”ë¡œê·¸', 'ë™ì•„ë¦¬', 'ìê²©ì¦'])
                
                ### Viewing the dataframe
                st.dataframe(df)
                
                ### Downloading Report of user_data in csv file
                st.markdown(get_csv_download_link(df,'User_Data.csv','ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ'), unsafe_allow_html=True)

                ### Fetch feedback data from user_feedback(table) and convert it into dataframe
                cursor.execute('''SELECT * from user_feedback''')
                data = cursor.fetchall()

                st.header("**ì‚¬ìš©ì í”¼ë“œë°± ë°ì´í„°**")
                df = pd.DataFrame(data, columns=['ID', 'ì´ë¦„', 'ì´ë©”ì¼', 'í”¼ë“œë°± ì ìˆ˜', 'ì½”ë©˜íŠ¸', 'íƒ€ì„ìŠ¤íƒ¬í”„'])
                st.dataframe(df)

                ### query to fetch data from user_feedback(table)
                query = 'select * from user_feedback'
                plotfeed_data = pd.read_sql(query, connection)                        

                ### Analyzing All the Data's in pie charts

                # fetching feed_score from the query and getting the unique values and total value count 
                labels = plotfeed_data.feed_score.unique()
                values = plotfeed_data.feed_score.value_counts()
                
                # Pie chart for user ratings
                st.subheader("**ì‚¬ìš©ì í‰ì **")
                fig = px.pie(values=values, names=labels, title="1ì—ì„œ 5ê¹Œì§€ì˜ ì‚¬ìš©ì í‰ì  ì°¨íŠ¸ ğŸ¤—", color_discrete_sequence=px.colors.sequential.Aggrnyl)
                st.plotly_chart(fig)

                # fetching Predicted_Field from the query and getting the unique values and total value count                 
                labels = plot_data.Predicted_Field.unique()
                values = plot_data.Predicted_Field.value_counts()

                # Pie chart for predicted field recommendations
                st.subheader("**ì˜ˆì¸¡ ë¶„ì•¼ ì¶”ì²œì„ ìœ„í•œ ì°¨íŠ¸**")
                fig = px.pie(df, values=values, names=labels, title='ê¸°ìˆ ì— ë”°ë¥¸ ì˜ˆì¸¡ ë¶„ì•¼ì˜ íŒŒì´ ì°¨íŠ¸ ğŸ‘½', color_discrete_sequence=px.colors.sequential.Aggrnyl_r)
                st.plotly_chart(fig)

                # fetching User_Level from the query and getting the unique values and total value count                 
                labels = plot_data.User_Level.unique()
                values = plot_data.User_Level.value_counts()

                # Pie chart for User'sğŸ‘¨â€ğŸ’» Experienced Level
                st.subheader("**ì‚¬ìš©ìì˜ ê²½í—˜ ìˆ˜ì¤€ì„ ìœ„í•œ ì°¨íŠ¸**")
                fig = px.pie(df, values=values, names=labels, title="ì°¨íŠ¸ ğŸ“ˆ for ì‚¬ìš©ìì˜ ğŸ‘¨â€ğŸ’» ê²½í—˜ ìˆ˜ì¤€", color_discrete_sequence=px.colors.sequential.RdBu)
                st.plotly_chart(fig)

                # fetching resume_score from the query and getting the unique values and total value count                 
                labels = plot_data.resume_score.unique()                
                values = plot_data.resume_score.value_counts()

                # Pie chart for Resume Score
                st.subheader("**ì´ë ¥ì„œ ì ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì°¨íŠ¸**")
                fig = px.pie(df, values=values, names=labels, title='1ë¶€í„° 100ê¹Œì§€ ğŸ’¯', color_discrete_sequence=px.colors.sequential.Agsunset)
                st.plotly_chart(fig)

                # fetching IP_add from the query and getting the unique values and total value count 
                labels = plot_data.IP_add.unique()
                values = plot_data.IP_add.value_counts()

                # Pie chart for Users
                st.subheader("**ì‚¬ìš©ì ì•± ì‚¬ìš© íšŸìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì°¨íŠ¸**")
                fig = px.pie(df, values=values, names=labels, title='IP ì£¼ì†Œ ê¸°ë°˜ ì‚¬ìš©ëŸ‰ ğŸ‘¥', color_discrete_sequence=px.colors.sequential.matter_r)
                st.plotly_chart(fig)

                # fetching City from the query and getting the unique values and total value count 
                labels = plot_data.City.unique()
                values = plot_data.City.value_counts()

                # Pie chart for City
                st.subheader("**ë„ì‹œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì°¨íŠ¸**")
                fig = px.pie(df, values=values, names=labels, title='ë„ì‹œ ê¸°ë°˜ ì‚¬ìš©ëŸ‰ ğŸŒ†', color_discrete_sequence=px.colors.sequential.Jet)
                st.plotly_chart(fig)

                # fetching State from the query and getting the unique values and total value count 
                labels = plot_data.State.unique()
                values = plot_data.State.value_counts()

                # Pie chart for State ë„ë¡œ ë²ˆì—­í–ˆìŠµë‹ˆë‹¤
                st.subheader("**í–‰ì • êµ¬ì—­(ë„)ì„ ë‚˜íƒ€ë‚´ëŠ” ì°¨íŠ¸**")
                fig = px.pie(df, values=values, names=labels, title='í–‰ì •êµ¬ì—­(ë„) ê¸°ë°˜ ì‚¬ìš©ëŸ‰ ğŸš‰', color_discrete_sequence=px.colors.sequential.PuBu_r)
                st.plotly_chart(fig)

                # fetching Country from the query and getting the unique values and total value count 
                labels = plot_data.Country.unique()
                values = plot_data.Country.value_counts()

                # Pie chart for Country
                st.subheader("**êµ­ê°€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì°¨íŠ¸**")
                fig = px.pie(df, values=values, names=labels, title='êµ­ê°€ ê¸°ë°˜ ì‚¬ìš©ëŸ‰  ğŸŒ', color_discrete_sequence=px.colors.sequential.Purpor_r)
                st.plotly_chart(fig)

            ## For Wrong Credentials
            else:
                st.error("ì˜ëª»ëœ ID ë° ë¹„ë°€ë²ˆí˜¸ê°€ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤. ")



# Calling the main (run()) function to make the whole process run
run()
